{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f95d001",
   "metadata": {},
   "source": [
    "# Na√ØveBayesClassifier\n",
    "for discrete values, \n",
    "without smoothening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0163c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc73d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv\n",
    "df = pd.read_csv(\"wbc_original.csv\")\n",
    "\n",
    "# to interpolate the missing values\n",
    "def fillNaN(df):\n",
    "    df.replace(\"?\", np.nan, inplace = True)\n",
    "    NaNcols = list()\n",
    "    for column in df.isnull().columns.values.tolist():\n",
    "        if df.isnull()[column].value_counts()[0] < df.shape[0]:\n",
    "            NaNcols.append(column)\n",
    "    for col in NaNcols:    \n",
    "        avg_norm_loss = df[col].astype(\"float\").mean(axis=0)\n",
    "        df[col].replace(np.nan, str(round(avg_norm_loss)), inplace=True) \n",
    "\n",
    "fillNaN(df)\n",
    "\n",
    "# Outlier Treatment\n",
    "def outlier_treatment(df, feature):\n",
    "    q1, q3 = np.percentile(df[feature], [25, 75])\n",
    "    IQR = q3 - q1 \n",
    "    lower_range = q1 - (3 * IQR) \n",
    "    upper_range = q3 + (3 * IQR)\n",
    "    to_drop = df[(df[feature]<lower_range)|(df[feature]>upper_range)]\n",
    "    df.drop(to_drop.index, inplace=True)\n",
    "\n",
    "outlier_treatment(df, 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88aec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the dataset + preprocessing\n",
    "df = df.drop(['id'], axis=1)\n",
    "X = df.drop(['class'], axis=1)\n",
    "Y = df['class']\n",
    "Xnames = X.columns\n",
    "#X is normalized\n",
    "# X = pd.DataFrame(normalize(X.values), columns = Xnames)\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4049afb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Features before removing multicollinearity:  Index(['clump_thickness', 'size_uniformity', 'shape_uniformity',\n",
      "       'marginal_adhesion', 'epithelial_size', 'bare_nucleoli',\n",
      "       'bland_chromatin', 'normal_nucleoli', 'mitoses'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Features after removing multicollinearity:\n",
      " ['clump_thickness', 'marginal_adhesion', 'epithelial_size', 'bare_nucleoli', 'bland_chromatin', 'normal_nucleoli', 'mitoses']\n"
     ]
    }
   ],
   "source": [
    "#Reducing multicollinearity\n",
    "final_features = [x for x in Xnames]\n",
    "p = df[Xnames].corr().values.tolist()\n",
    "for i in range(len(p)):\n",
    "    for j in range(i+1, len(p)):\n",
    "        if abs(p[i][j]) > 0.7 and Xnames[i] in final_features:\n",
    "            final_features.remove(Xnames[i])\n",
    "print(\"\\n\\nFeatures before removing multicollinearity: \", Xnames)\n",
    "print(\"\\n\\nFeatures after removing multicollinearity:\\n\", final_features)\n",
    "X = X[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e164e670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEMPCS~1.017\\AppData\\Local\\Temp/ipykernel_9684/2555535271.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['class'] = Y_train\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "train = X_train\n",
    "train['class'] = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c1f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = (train.groupby(\"class\").count() / len(train)).iloc[:,1] # Estimate prior probabilities\n",
    "classes = np.unique(train[\"class\"].tolist()) # Storing all possible classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb5f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2featcount= {}\n",
    "class4featcount= {}\n",
    "for column in train.columns[:-1]:\n",
    "    class2featcount[column] = {}\n",
    "    class4featcount[column] = {}\n",
    "    for featvalue in np.unique(train[column]):\n",
    "        featArr = train[[column, train.columns[-1]]]\n",
    "        class2featcount[column][featvalue] = featArr[(featArr[column] == featvalue) & (featArr[train.columns[-1]] == 2)].count()[0]\n",
    "        class4featcount[column][featvalue] = featArr[(featArr[column] == featvalue) & (featArr[train.columns[-1]] == 4)].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ba4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2count, class4count = np.unique(train['class'], return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7149e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2likelihood = {}\n",
    "for k, v in class2featcount.items():\n",
    "    class2likelihood[k] = {}\n",
    "    for kk, vv in v.items():\n",
    "        class2likelihood[k][kk]= vv/class2count\n",
    "class4likelihood = {}\n",
    "for k, v in class4featcount.items():\n",
    "    class4likelihood[k] = {}\n",
    "    for kk, vv in v.items():\n",
    "        class4likelihood[k][kk]= vv/class4count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e60199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_posterior(colvals):\n",
    "    class2 = class2count/train[train.columns[:-1]].size\n",
    "    class4 = class4count/train[train.columns[:-1]].size\n",
    "    for i,j in zip(train.columns[:-1], colvals):\n",
    "        class2 *= class2likelihood[i][j]\n",
    "        class4 *= class4likelihood[i][j]\n",
    "    return 2 if class2 > class4 else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1668dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in X_test.values:\n",
    "    pred.append(calc_posterior(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d1bd895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in zip(pred, Y_test.values):\n",
    "    if i == j:\n",
    "        count+=1\n",
    "print(\"Accuracy of the model: \", count/Y_test.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
