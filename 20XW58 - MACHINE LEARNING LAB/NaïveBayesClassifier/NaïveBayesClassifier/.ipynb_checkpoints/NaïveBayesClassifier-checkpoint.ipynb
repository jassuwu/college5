{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0163c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dc73d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv\n",
    "df = pd.read_csv(\"wbc_original.csv\")\n",
    "\n",
    "# to interpolate the missing values\n",
    "def fillNaN(df):\n",
    "    df.replace(\"?\", np.nan, inplace = True)\n",
    "    NaNcols = list()\n",
    "    for column in df.isnull().columns.values.tolist():\n",
    "        if df.isnull()[column].value_counts()[0] < df.shape[0]:\n",
    "            NaNcols.append(column)\n",
    "    for col in NaNcols:    \n",
    "        avg_norm_loss = df[col].astype(\"float\").mean(axis=0)\n",
    "        df[col].replace(np.nan, str(round(avg_norm_loss)), inplace=True) \n",
    "\n",
    "fillNaN(df)\n",
    "\n",
    "# Outlier Treatment\n",
    "def outlier_treatment(df, feature):\n",
    "    q1, q3 = np.percentile(df[feature], [25, 75])\n",
    "    IQR = q3 - q1 \n",
    "    lower_range = q1 - (3 * IQR) \n",
    "    upper_range = q3 + (3 * IQR)\n",
    "    to_drop = df[(df[feature]<lower_range)|(df[feature]>upper_range)]\n",
    "    df.drop(to_drop.index, inplace=True)\n",
    "\n",
    "outlier_treatment(df, 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a88aec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the dataset + preprocessing\n",
    "df = df.drop(['id'], axis=1)\n",
    "X = df.drop(['class'], axis=1)\n",
    "Y = df['class']\n",
    "Xnames = X.columns\n",
    "#X is normalized\n",
    "# X = pd.DataFrame(normalize(X.values), columns = Xnames)\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4049afb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Features before removing multicollinearity:  Index(['clump_thickness', 'size_uniformity', 'shape_uniformity',\n",
      "       'marginal_adhesion', 'epithelial_size', 'bare_nucleoli',\n",
      "       'bland_chromatin', 'normal_nucleoli', 'mitoses'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Features after removing multicollinearity:\n",
      " ['clump_thickness', 'marginal_adhesion', 'epithelial_size', 'bare_nucleoli', 'bland_chromatin', 'normal_nucleoli', 'mitoses']\n"
     ]
    }
   ],
   "source": [
    "#Reducing multicollinearity\n",
    "final_features = [x for x in Xnames]\n",
    "p = df[Xnames].corr().values.tolist()\n",
    "for i in range(len(p)):\n",
    "    for j in range(i+1, len(p)):\n",
    "        if abs(p[i][j]) > 0.7 and Xnames[i] in final_features:\n",
    "            final_features.remove(Xnames[i])\n",
    "print(\"\\n\\nFeatures before removing multicollinearity: \", Xnames)\n",
    "print(\"\\n\\nFeatures after removing multicollinearity:\\n\", final_features)\n",
    "X = X[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e164e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6c1f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prior_prob(Y):\n",
    "    uniq, count = np.unique(Y_train, return_counts=True)\n",
    "    res = dict()\n",
    "    for i,j in zip(uniq, count):\n",
    "        res.update({str(i):j/Y.size})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0899475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 0.667262969588551, '4': 0.33273703041144903}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_prior_prob(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5986c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "forCPT = X\n",
    "forCPT['class'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc42bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in forCPT[::-1]:\n",
    "    for featvalue in np.unique(forCPT[column]):\n",
    "        class2featcount = forCPT[(forCPT[column] == featvalue) & (forCPT['class'] == 2)][[column, 'class']].count()[0]\n",
    "        class4featcount = forCPT[(forCPT[column] == featvalue)][[column, 'class']].count() - class2featcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c4aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f7289b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False,  True, False,  True, False, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False,  True, False, False, False, False,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "        True,  True, False, False,  True, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False,  True,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False,  True,  True, False, False,  True,\n",
       "       False,  True, False,  True, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True, False,  True, False, False, False,  True,  True,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True,  True, False,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "        True, False,  True, False, False,  True,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True,  True,  True, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True,  True, False,  True,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(forCPT['clump_thickness'] == 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af814b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
